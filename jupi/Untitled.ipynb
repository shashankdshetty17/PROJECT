{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8599e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162d85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df=pd.read_csv(\"fake.csv\")\n",
    "    print(\"reading done\")\n",
    "    print(df.size)\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_cleaning(df):\n",
    "    \n",
    "    # Pre-processing Text Reviews\n",
    "    # Remove Stop Words\n",
    "    stop = stopwords.words('english')\n",
    "    df['text_'] = df['text_'].apply(\n",
    "        lambda x: ' '.join(word for word in str(x).split() if word not in stop))\n",
    "\n",
    "    # Remove Punctuations\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df['text_'] = df['text_'].apply(\n",
    "        lambda x: ' '.join(word for word in tokenizer.tokenize(x)))\n",
    "\n",
    "    # Lowercase Words\n",
    "    df['text_'] = df['text_'].apply(\n",
    "        lambda x: str(x).lower())\n",
    "    \n",
    "    df.drop([ 'category'], axis=1, inplace=True)\n",
    "  \n",
    "    print(\"Data Cleaning Complete\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc01982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, batch_size=3000):\n",
    "    print(\"Feature Engineering: Creating New Features\")\n",
    "\n",
    "    def process_batch(batch):\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        for index, row in batch.iterrows():\n",
    "            text1 = row['text_']\n",
    "            sentiment_dict = sid.polarity_scores(text1)\n",
    "            df.at[index, 'sentiment'] = sentiment_dict['compound']\n",
    "\n",
    "        def text_process(review):\n",
    "            nopunc = [char for char in review if char not in string.punctuation]\n",
    "            nopunc = ''.join(nopunc)\n",
    "            return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "        bow_transformer = CountVectorizer(analyzer=text_process)\n",
    "        bow_transformer.fit(batch['text_'])\n",
    "        print(\"Batch Vocabulary:\", len(bow_transformer.vocabulary_))\n",
    "\n",
    "        bow_reviews = bow_transformer.transform(batch['text_'])\n",
    "\n",
    "        tfidf_transformer = TfidfTransformer().fit(bow_reviews)\n",
    "        tfidf_reviews = tfidf_transformer.transform(bow_reviews)\n",
    "        df.loc[batch.index, 'tfidf'] = pd.Series(tfidf_reviews.toarray().tolist())\n",
    "\n",
    "    # Split data into batches\n",
    "    num_batches = int(np.ceil(len(df) / batch_size))\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(df))\n",
    "        batch = df.iloc[batch_start:batch_end].copy()\n",
    "        process_batch(batch)\n",
    "\n",
    "    print(\"Feature Engineering Complete\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f051a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(df):\n",
    "    print(\"Under-Sampling Data\")\n",
    "    # Count of Reviews\n",
    "    # print(\"Authentic\", len(df[(df['flagged'] == 'N')]))\n",
    "    # print(\"Fake\", len(df[(df['flagged'] == 'Y')]))\n",
    "\n",
    "    sample_size = len(df[(df['label'] == 'OR')])\n",
    "\n",
    "    authentic_reviews_df = df[df['label'] == 'OR']\n",
    "    fake_reviews_df = df[df['label'] == 'CG']\n",
    "\n",
    "    authentic_reviews_us_df = authentic_reviews_df.sample(sample_size)\n",
    "    under_sampled_df = pd.concat([authentic_reviews_us_df, fake_reviews_df], axis=0)\n",
    "\n",
    "    print(\"Under-Sampling Complete\")\n",
    "    return under_sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68092504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_learning(df, model, algorithm, threshold=0.8, iterations=40):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['label']\n",
    "\n",
    "    df.drop([ 'label','text_'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.3, random_state=40)\n",
    "\n",
    "    test_data_copy = test_data.copy()\n",
    "    test_label_copy = test_label.copy()\n",
    "\n",
    "    all_labeled = False\n",
    "\n",
    "    current_iteration = 0\n",
    "\n",
    "    pbar = tqdm(total=iterations)\n",
    "\n",
    "    while not all_labeled and (current_iteration < iterations):\n",
    "        # print(\"Before train data length : \", len(train_data))\n",
    "        # print(\"Before test data length : \", len(test_data))\n",
    "        current_iteration += 1\n",
    "        model.fit(train_data, train_label)\n",
    "\n",
    "        probabilities = model.predict_proba(test_data)\n",
    "        pseudo_labels = model.predict(test_data)\n",
    "\n",
    "        indices = np.argwhere(probabilities > threshold)\n",
    "\n",
    "        # print(\"rows above threshold : \", len(indices))\n",
    "        for item in indices:\n",
    "            train_data.loc[test_data.index[item[0]]] = test_data.iloc[item[0]]\n",
    "            train_label.loc[test_data.index[item[0]]] = pseudo_labels[item[0]]\n",
    "        test_data.drop(test_data.index[indices[:, 0]], inplace=True)\n",
    "        test_label.drop(test_label.index[indices[:, 0]], inplace=True)\n",
    "        # print(\"After train data length : \", len(train_data))\n",
    "        # print(\"After test data length : \", len(test_data))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            print(\"Exiting loop\")\n",
    "            all_labeled = True\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    predicted_labels = model.predict(test_data_copy)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label_copy, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label_copy, predicted_labels, pos_label=\"CG\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label_copy, predicted_labels, pos_label=\"CG\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label_copy, predicted_labels, pos_label=\"CG\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label_copy, predicted_labels)))\n",
    "    #plot_confusion_matrix(test_label_copy, predicted_labels, classes=['OR', 'CG'],title=algorithm + ' Confusion Matrix').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71aa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time()\n",
    "    df = load_data()\n",
    "    print(df)\n",
    "    df = data_cleaning(df)\n",
    "    print(df)\n",
    "    df = feature_engineering(df)\n",
    "    #under_sampled_df = df\n",
    "    under_sampled_df = under_sampling(df)\n",
    "    rf = RandomForestClassifier(random_state=42, criterion='entropy', max_depth=14, max_features='sqrt',n_estimators=500)\n",
    "    nb = GaussianNB()\n",
    "    print(df)\n",
    "    semi_supervised_learning(under_sampled_df, model=rf, threshold=0.8, iterations=5, algorithm='Random Forest')\n",
    "    semi_supervised_learning(under_sampled_df, model=nb, threshold=0.8, iterations=5, algorithm='Naive Bayes')\n",
    "    end_time = time()\n",
    "    print(\"Time taken : \", end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1995d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading done\n",
      "162376\n",
      "                 category  rating label  \\\n",
      "0      Home_and_Kitchen_5     5.0    CG   \n",
      "1      Home_and_Kitchen_5     5.0    CG   \n",
      "2      Home_and_Kitchen_5     5.0    CG   \n",
      "3      Home_and_Kitchen_5     1.0    CG   \n",
      "4      Home_and_Kitchen_5     5.0    CG   \n",
      "...                   ...     ...   ...   \n",
      "40589       Electronics_5     4.0    OR   \n",
      "40590       Electronics_5     4.0    OR   \n",
      "40591       Electronics_5     4.0    OR   \n",
      "40592       Electronics_5     4.0    OR   \n",
      "40593       Electronics_5     4.0    OR   \n",
      "\n",
      "                                                   text_  \n",
      "0      Love this!  Well made, sturdy, and very comfor...  \n",
      "1      love it, a great upgrade from the original.  I...  \n",
      "2      This pillow saved my back. I love the look and...  \n",
      "3      Missing information on how to use it, but it i...  \n",
      "4      Very nice set. Good quality. We have had the s...  \n",
      "...                                                  ...  \n",
      "40589                                       nice product  \n",
      "40590                              Charging as expected.  \n",
      "40591                               Awesome and fabulous  \n",
      "40592                         Best Charger For IPhone 12  \n",
      "40593                         Very good product must buy  \n",
      "\n",
      "[40594 rows x 4 columns]\n",
      "Data Cleaning Complete\n",
      "       rating label                                              text_\n",
      "0         5.0    CG  love this well made sturdy comfortable i love ...\n",
      "1         5.0    CG  love it great upgrade original i ve mine coupl...\n",
      "2         5.0    CG     this pillow saved back i love look feel pillow\n",
      "3         1.0    CG   missing information use it great product price i\n",
      "4         5.0    CG       very nice set good quality we set two months\n",
      "...       ...   ...                                                ...\n",
      "40589     4.0    OR                                       nice product\n",
      "40590     4.0    OR                                  charging expected\n",
      "40591     4.0    OR                                   awesome fabulous\n",
      "40592     4.0    OR                         best charger for iphone 12\n",
      "40593     4.0    OR                         very good product must buy\n",
      "\n",
      "[40594 rows x 3 columns]\n",
      "Feature Engineering: Creating New Features\n",
      "Batch Vocabulary: 4880\n",
      "Batch Vocabulary: 8452\n",
      "Batch Vocabulary: 9283\n",
      "Batch Vocabulary: 8988\n",
      "Batch Vocabulary: 9352\n",
      "Batch Vocabulary: 12550\n",
      "Batch Vocabulary: 8795\n",
      "Batch Vocabulary: 8561\n",
      "Batch Vocabulary: 6793\n",
      "Batch Vocabulary: 11508\n",
      "Batch Vocabulary: 14885\n",
      "Batch Vocabulary: 5531\n",
      "Batch Vocabulary: 7703\n",
      "Batch Vocabulary: 6419\n",
      "Feature Engineering Complete\n",
      "Under-Sampling Data\n",
      "Under-Sampling Complete\n",
      "       rating label                                              text_  \\\n",
      "0         5.0    CG  love this well made sturdy comfortable i love ...   \n",
      "1         5.0    CG  love it great upgrade original i ve mine coupl...   \n",
      "2         5.0    CG     this pillow saved back i love look feel pillow   \n",
      "3         1.0    CG   missing information use it great product price i   \n",
      "4         5.0    CG       very nice set good quality we set two months   \n",
      "...       ...   ...                                                ...   \n",
      "40589     4.0    OR                                       nice product   \n",
      "40590     4.0    OR                                  charging expected   \n",
      "40591     4.0    OR                                   awesome fabulous   \n",
      "40592     4.0    OR                         best charger for iphone 12   \n",
      "40593     4.0    OR                         very good product must buy   \n",
      "\n",
      "       sentiment                                              tfidf  \n",
      "0         0.9538  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1         0.8910  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2         0.7906  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3         0.4404  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4         0.7397  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "...          ...                                                ...  \n",
      "40589     0.4215                                                NaN  \n",
      "40590     0.0000                                                NaN  \n",
      "40591     0.8176                                                NaN  \n",
      "40592     0.6369                                                NaN  \n",
      "40593     0.4927                                                NaN  \n",
      "\n",
      "[40594 rows x 5 columns]\n",
      "Training Random Forest Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m nb \u001b[38;5;241m=\u001b[39m GaussianNB()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m---> 13\u001b[0m \u001b[43msemi_supervised_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43munder_sampled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRandom Forest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m semi_supervised_learning(under_sampled_df, model\u001b[38;5;241m=\u001b[39mnb, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m, in \u001b[0;36msemi_supervised_learning\u001b[1;34m(df, model, algorithm, threshold, iterations)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_labeled \u001b[38;5;129;01mand\u001b[39;00m (current_iteration \u001b[38;5;241m<\u001b[39m iterations):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# print(\"Before train data length : \", len(train_data))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# print(\"Before test data length : \", len(test_data))\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     current_iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(test_data)\n\u001b[0;32m     26\u001b[0m     pseudo_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db0512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
